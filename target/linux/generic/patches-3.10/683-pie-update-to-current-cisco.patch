From fce62a205a5b0a55eb4606248a945f53562c0fa1 Mon Sep 17 00:00:00 2001
From: Dave Taht <dave.taht@bufferbloat.net>
Date: Tue, 20 Aug 2013 14:30:31 -0700
Subject: [PATCH] pie: update to latest cisco code

This updates to the latest cisco code which handles falling
back to a lower drop state more correctly.

Unlike the cisco code drop it preserves byte mode and keeps
in the ecn support as well as the internal congestion
notification code similarly to RED and codel.

Like the cisco code drop it disables byte mode by default.
ECN is also disabled by default.
---
 net/sched/sch_pie.c |  255 +++++++++++++++++++++++++++++----------------------
 1 file changed, 144 insertions(+), 111 deletions(-)

diff --git a/net/sched/sch_pie.c b/net/sched/sch_pie.c
index de1c519e..e35b4b5 100644
--- a/net/sched/sch_pie.c
+++ b/net/sched/sch_pie.c
@@ -1,35 +1,19 @@
-/*
- *  Copyright (C) 2013 Cisco Systems, Inc, 2013. All rights reserved.
+/* 
+ * Copyright (C) 2013 Cisco Systems, Inc, 2013. All rights reserved.
  *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions, and the following disclaimer,
- *    without modification.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- * 3. The names of the authors may not be used to endorse or promote products
- *    derived from this software without specific prior written permission.
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License.
  *
- * Alternatively, provided that this notice is retained in full, this
- * software may be distributed under the terms of the GNU General
- * Public License ("GPL") version 2, in which case the provisions of the
- * GPL apply INSTEAD OF those given above.
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
  *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
- * DAMAGE.
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
  *
  * Author: Vijay Subramanian <vijaynsu@cisco.com>
  * Author: Mythili Prabhu <mysuryan@cisco.com>
@@ -45,11 +29,13 @@
 #include <net/pkt_sched.h>
 #include <net/inet_ecn.h>
 
-#define PIE_DEFAULT_QUEUE_LIMIT 1000		/* in packets */
-#define QUEUE_THRESHOLD		(10*1500)	/* 10 Ethernet packets worth */
-#define DQCOUNT_INVALID	-1
+#define PIE_DEFAULT_QUEUE_LIMIT 1000	/*in packets */
+#define QUEUE_THRESHOLD (5000)	/* 10 Ethernet packets worth */
+#define DQCOUNT_INVALID -1
 #define THRESHOLD_PKT_SIZE	1500
+static const unsigned int MAX_INT_VALUE = 0xffffffff;
 
+/* parameters used*/
 struct pie_params {
 	u32 target;		/* user specified target delay, we convert
 				   from ms and store as jiffies */
@@ -63,6 +49,7 @@ struct pie_params {
 	bool ecn;		/* use ECN */
 };
 
+/* variables used*/
 struct pie_vars {
 	u32 prob;		/* probability but scaled by u32 limit. */
 	u32 burst_time;		/* in jiffies */
@@ -71,7 +58,7 @@ struct pie_vars {
 	u32 dq_count;		/* measured in bytes */
 	u64 dq_timestamp;	/* 64 bit timestamp */
 	u32 avg_dq_rate;	/* bytes per jiffy or bytes per target ms? */
-	u32 qlen_old;		/* bytes, the current qlen in bytes is
+	u32 qlen_old;		/* bytes, the current qlen in bytes is 
 				   maintained in sch->qstats.backlog */
 };
 
@@ -80,25 +67,32 @@ struct pie_stats {
 	u32 dropped;		/* packets dropped due to pie_action */
 	u32 overlimit;		/* dropped due to lack of space in queue */
 	u32 maxq;		/* maximum queue size */
-	u32 ecn_mark;
+	u32 ecn_mark;		/* packets marked rather than dropped */
 };
 
 static void pie_params_init(struct pie_params *params)
 {
-	params->small = true;
-	params->ecn = false;
+	memset(params, 0, sizeof(*params));
 	params->alpha = 2;
 	params->beta = 20;
-	params->tupdate = msecs_to_jiffies(30);
-	params->target = msecs_to_jiffies(20);
+	params->tupdate = (30 * HZ) / 1000;	/* 30 ms */
 	params->limit = PIE_DEFAULT_QUEUE_LIMIT;
+	params->target = (20 * HZ) / 1000;	/* 20 ms */
+	params->ecn = false;
+	params->small = false;
 }
 
 static void pie_vars_init(struct pie_vars *vars)
 {
 	memset(vars, 0, sizeof(*vars));
 	vars->dq_count = DQCOUNT_INVALID;
-	vars->burst_time = msecs_to_jiffies(100);
+	vars->avg_dq_rate = 0;
+	vars->burst_time = HZ / 10;	/* default of 100 ms */
+}
+
+static void pie_stats_init(struct pie_stats *stats)
+{
+	memset(stats, 0, sizeof(*stats));
 }
 
 struct pie_sched_data {
@@ -108,22 +102,22 @@ struct pie_sched_data {
 	struct timer_list adapt_timer;
 };
 
-static bool drop_early(struct Qdisc *sch, u32 packet_size)
+static inline bool drop_early(struct Qdisc *sch, u32 packet_size)
 {
-	struct pie_sched_data *q = qdisc_priv(sch);
 	u32 local_prob;
+	struct pie_sched_data *q = qdisc_priv(sch);
 
 	/* If there is still burst allowance left or delay is much below
-	 * target (and not due to heavy dropping), skip random early drop
+	 * target not due to heavy dropping, skip random early drop 
 	 */
 	if (q->vars.burst_time > 0)
 		return false;
 
-	/* If current delay is less than half of target, and
+	/* If current delay is less than half of target, and 
 	 * if drop prob is low already, disable early_drop
 	 */
 	if ((q->vars.qdelay < q->params.target / 2)
-	    && (q->vars.prob < UINT_MAX / 5))
+	    && (q->vars.prob < MAX_INT_VALUE / 5))
 		return false;
 
 	/* If we have fewer than 2 packets, disable drop_early, similar to
@@ -149,31 +143,30 @@ static bool drop_early(struct Qdisc *sch, u32 packet_size)
 
 static int pie_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch)
 {
-	bool drop;
 	struct pie_sched_data *q = qdisc_priv(sch);
+
 	if (unlikely(qdisc_qlen(sch) >= sch->limit))
 		goto out;
 
-	drop = drop_early(sch, skb->len);
-	if (!drop) {
+	if (!drop_early(sch, skb->len)) {
+		/* we can enqueue the packet */
 		q->stats.packets_in++;
 		if (qdisc_qlen(sch) > q->stats.maxq)
 			q->stats.maxq = qdisc_qlen(sch);
-		return qdisc_enqueue_tail(skb, sch);
 
-	} else if(q->params.ecn && INET_ECN_set_ce(skb)) {
+		return qdisc_enqueue_tail(skb, sch);
+	} else if (q->params.ecn && INET_ECN_set_ce(skb)) {
 		q->stats.packets_in++;
+		q->stats.ecn_mark++;
 		if (qdisc_qlen(sch) > q->stats.maxq)
 			q->stats.maxq = qdisc_qlen(sch);
-		q->stats.ecn_mark++;
 		return qdisc_enqueue_tail(skb, sch);
-	}
+	  }
 
 out:
 	q->stats.overlimit++;
 	qdisc_drop(skb, sch);
 	return NET_XMIT_CN;
-
 }
 
 static const struct nla_policy pie_policy[TCA_PIE_MAX + 1] = {
@@ -183,7 +176,7 @@ static const struct nla_policy pie_policy[TCA_PIE_MAX + 1] = {
 	[TCA_PIE_ALPHA]    = { .type = NLA_U32 },
 	[TCA_PIE_BETA]     = { .type = NLA_U32 },
 	[TCA_PIE_BYTEMODE] = { .type = NLA_U32 },
-	[TCA_PIE_ECN]	   = { .type = NLA_U32 },
+	[TCA_PIE_ECN]      = { .type = NLA_U32 },
 };
 
 static int pie_change(struct Qdisc *sch, struct nlattr *opt)
@@ -202,16 +195,21 @@ static int pie_change(struct Qdisc *sch, struct nlattr *opt)
 
 	sch_tree_lock(sch);
 
-	if (tb[TCA_PIE_TARGET])
-		q->params.target =
-			msecs_to_jiffies(nla_get_u32(tb[TCA_PIE_TARGET]));
-
-	if (tb[TCA_PIE_TUPDATE])
-		q->params.tupdate =
-			msecs_to_jiffies(nla_get_u32(tb[TCA_PIE_TUPDATE]));
+	if (tb[TCA_PIE_TARGET]) {
+		u32 target = nla_get_u32(tb[TCA_PIE_TARGET]);
+		/* convert from ms to jiffies */
+		q->params.target = (target * HZ) / (1000);
+	}
+	if (tb[TCA_PIE_TUPDATE]) {
+		u32 tupdate = nla_get_u32(tb[TCA_PIE_TUPDATE]);
+		q->params.tupdate = (tupdate * HZ) / (1000);
+	}
 
-	if (tb[TCA_PIE_LIMIT])
-		q->params.limit = sch->limit = nla_get_u32(tb[TCA_PIE_LIMIT]);
+	if (tb[TCA_PIE_LIMIT]) {
+		u32 limit = nla_get_u32(tb[TCA_PIE_LIMIT]);
+		q->params.limit = limit;
+		sch->limit = limit;
+	}
 
 	if (tb[TCA_PIE_ALPHA])
 		q->params.alpha = nla_get_u32(tb[TCA_PIE_ALPHA]);
@@ -246,8 +244,8 @@ static int pie_process_dequeue(struct Qdisc *sch, struct sk_buff *skb)
 	int qlen = sch->qstats.backlog;	/* current queue size in bytes */
 
 	/* If current queue is about 10 packets or more and dq_count is
-	 * less than 0, we have enough packets
-	 * to calculate the drain rate. Save current time as dq_timestamp
+	 * less than 0, we have enough packets to calculate the drain rate. 
+	 * Save current time as dq_timestamp.
 	 */
 
 	if (qlen >= QUEUE_THRESHOLD && q->vars.dq_count == DQCOUNT_INVALID) {
@@ -256,12 +254,12 @@ static int pie_process_dequeue(struct Qdisc *sch, struct sk_buff *skb)
 	}
 
 	/* Calculate the average drain rate from this value.  If queue length
-	 * has receded to a small value viz., <=10 packets,reset the dq_count
-	 * to -1 as we don't have enough packets to calculate the drain rate
+	 * has receded to a small value viz., <=10 packets,reset the dq_count to
+	 * -1 as we don't have enough packets to calculate the drain rate
 	 * anymore The following if block is entered only when we have a
 	 * substantial queue built up (10 packets or more) and we calculate the
-	 * drain rate for 10 packets here.  dq_count is in bytes time
-	 * difference in ms, hence rate is in bytes/ms.
+	 * drain rate for 10 packets here.  dq_count is in bytes time difference
+	 * in ms, hence rate is in bytes/ms
 	 */
 
 	if (q->vars.dq_count != DQCOUNT_INVALID) {
@@ -280,13 +278,12 @@ static int pie_process_dequeue(struct Qdisc *sch, struct sk_buff *skb)
 			if (q->vars.avg_dq_rate == 0)
 				q->vars.avg_dq_rate = count;
 			else
-				q->vars.avg_dq_rate = (q->vars.avg_dq_rate -
-				    (q->vars.avg_dq_rate >> 3)) + (count >> 3);
+				q->vars.avg_dq_rate =
+				    (q->vars.avg_dq_rate -
+				     (q->vars.avg_dq_rate >> 3)) + (count >> 3);
 
-			/* If the queue receded below the threshold, we hold
-			 * on to the last drain rate calculated,
-			 * else we reset dq_count to 0 to re-enter the if block
-			 * when the next packet is dequeued.
+			/* If the queue has receded below the threshold, we hold on to the last drain rate calculated,
+			 * else we reset dq_count to 0 to re-enter the if block when the next packet is dequeued
 			 */
 
 			if (qlen < QUEUE_THRESHOLD)
@@ -311,13 +308,13 @@ static int pie_process_dequeue(struct Qdisc *sch, struct sk_buff *skb)
 static void calculate_probability(struct Qdisc *sch)
 {
 	struct pie_sched_data *q = qdisc_priv(sch);
-	int qlen = sch->qstats.backlog;		/* queue size in bytes */
-	int qdelay = 0;				/* in jiffies */
+	int qlen = sch->qstats.backlog;	/* queue size in bytes */
+	int qdelay = 0;		/* in jiffies */
 	int qdelay_old = q->vars.qdelay;	/* in jiffies */
-	s32 delta = 0;				/* signed difference */
+	s32 delta = 0;		/* signed difference */
 	u32 oldprob;
 	u32 alpha, beta;
-
+	bool update_prob = true;  /* Should probability be updated?*/
 	q->vars.qdelay_old = q->vars.qdelay;
 
 	if (q->vars.avg_dq_rate > 0)
@@ -325,60 +322,84 @@ static void calculate_probability(struct Qdisc *sch)
 	else
 		qdelay = 0;
 
-	/* Add ranges for alpha and beta, more aggressive for high dropping
-	 * mode and gentle steps for light dropping mode
+	/* If qdelay is zero and qlen is not, it means qlen is very small, less
+	* that dequeue_rate, so we do not update probabilty in this round */
+	if (qdelay == 0 && qlen != 0)
+		update_prob = false;
+
+	/* Add ranges for alpha and beta, more aggressive for high dropping 
+	 * mode and gentle steps for light dropping mode 
 	 * In light dropping mode, take gentle steps; in medium dropping mode,
 	 * take medium steps; in high dropping mode, take big steps.
 	 */
-	if (q->vars.prob < UINT_MAX / 100) {
-		alpha = (q->params.alpha * (UINT_MAX / HZ)) >> 7;
-		beta = (q->params.beta * (UINT_MAX / HZ)) >> 7;
-	} else if (q->vars.prob < UINT_MAX / 10) {
-		alpha = (q->params.alpha * (UINT_MAX / HZ)) >> 5;
-		beta = (q->params.beta * (UINT_MAX / HZ)) >> 5;
+	if (q->vars.prob < MAX_INT_VALUE / 100) {
+		alpha = (q->params.alpha * (MAX_INT_VALUE / HZ)) >> 7;
+		beta = (q->params.beta * (MAX_INT_VALUE / HZ)) >> 7;
+	} else if (q->vars.prob < MAX_INT_VALUE / 10) {
+		alpha = (q->params.alpha * (MAX_INT_VALUE / HZ)) >> 5;
+		beta = (q->params.beta * (MAX_INT_VALUE / HZ)) >> 5;
 	} else {
-		alpha = (q->params.alpha * (UINT_MAX / HZ)) >> 4;
-		beta = (q->params.beta * (UINT_MAX / HZ)) >> 4;
+		alpha = (q->params.alpha * (MAX_INT_VALUE / HZ)) >> 4;
+		beta = (q->params.beta * (MAX_INT_VALUE / HZ)) >> 4;
 	}
 
 	/* alpha and beta should be between 0 and 32, in multiples of 1/16 */
-
 	delta += alpha * ((qdelay - q->params.target));
 	delta += beta * ((qdelay - qdelay_old));
 
 	oldprob = q->vars.prob;
 
-	/* Ensure we increase probability in steps of no more than 2% */
+	/* addition to ensure we increase probability in steps of no
+	 *  more than 2%
+	 */
 
-	if (delta > (s32) (UINT_MAX / 200) && q->vars.prob >= UINT_MAX / 10)
-		delta = UINT_MAX / 200;
+	if (delta > (s32) (MAX_INT_VALUE * 2 / 100)
+	    && q->vars.prob >= MAX_INT_VALUE / 10) {
+		delta = MAX_INT_VALUE * 2 / 100;
+	}
 
-	/* Non-linear drop */
-	if (qdelay > (250 * HZ) / 1000)
-		delta = (2 * UINT_MAX) / 100;
+	/*  Non-linear drop 
+	*  Tune drop probability to increase quickly for high delays (250ms and above)
+	*  250ms is derived through experiments and provides error protection
+	*/
+	if (qdelay > ((250 * HZ) / 1000))
+		delta += (2 * MAX_INT_VALUE) / 100;
 
 	q->vars.prob += delta;
 
 	if (delta > 0) {
 		/* prevent overflow */
-		if (q->vars.prob < oldprob)
-			q->vars.prob = UINT_MAX;
+		if (q->vars.prob < oldprob) {
+			q->vars.prob = MAX_INT_VALUE;
+			/*  Prevent normalization error
+			 * If probability is the maximum value already, we normalize it here, and skip the
+			 * check to do a non-linear drop in the next section 
+			 */
+			update_prob = false;
+		}
 	} else {
 		/* prevent underflow */
 		if (q->vars.prob > oldprob)
 			q->vars.prob = 0;
 	}
 
-	/* for non-linear drop in probability */
-	if (qdelay == 0 && qdelay_old == 0)
-		q->vars.prob = (q->vars.prob * 98)/100;
+	/* Non-linear drop in probability */
+	/* Reduce drop probability quickly if delay is 0 for 2 consecutive Tupdate periods */
+	if ((qdelay == 0) && (qdelay_old == 0) && update_prob)
+		q->vars.prob = (q->vars.prob * 98) / 100;
 
 	q->vars.qdelay = qdelay;
 	q->vars.qlen_old = qlen;
 
-	if ((q->vars.qdelay < q->params.target / 2) &&
-	    (q->vars.qdelay_old < q->params.target / 2) &&
-	     q->vars.prob == 0)
+	/* we restart the measurement cycle if the following conditions are met 
+	*  1. If the delay has been low for 2 consecutive Tupdate periods
+	*  2. Calculated drop probability is zero
+	*  3. We have atleast one estimate for the avg_dq_rate ie., is a non-zero value
+	*/
+	if ((q->vars.qdelay < q->params.target / 2)
+	    && (q->vars.qdelay_old < q->params.target / 2)
+	    && (q->vars.prob == 0)
+	    && q->vars.avg_dq_rate > 0)
 		pie_vars_init(&q->vars);
 }
 
@@ -389,8 +410,11 @@ static inline void pie_timer(unsigned long arg)
 
 	calculate_probability(sch);
 
-	/* reset the timer to fire after 'tupdate' ms, tupdate is in jiffies */
+	/* reset the timer to fire after  'tupdate' ms, tupdate is in jiffies */
 	mod_timer(&q->adapt_timer, jiffies + q->params.tupdate);
+
+	return;
+
 }
 
 static int pie_init(struct Qdisc *sch, struct nlattr *opt)
@@ -399,7 +423,7 @@ static int pie_init(struct Qdisc *sch, struct nlattr *opt)
 
 	pie_params_init(&q->params);
 	pie_vars_init(&q->vars);
-
+	pie_stats_init(&q->stats);
 	sch->limit = q->params.limit;
 	setup_timer(&q->adapt_timer, pie_timer, (unsigned long)sch);
 	add_timer(&q->adapt_timer);
@@ -431,14 +455,17 @@ static int pie_dump(struct Qdisc *sch, struct sk_buff *skb)
 
 	/* convert target and tupdate from jiffies to ms */
 	if (nla_put_u32(skb, TCA_PIE_TARGET,
-			jiffies_to_msecs(q->params.target)) ||
-	    nla_put_u32(skb, TCA_PIE_LIMIT, sch->limit) ||
+			(q->params.target * 1000) / HZ) ||
+	    nla_put_u32(skb, TCA_PIE_LIMIT,
+			sch->limit) ||
 	    nla_put_u32(skb, TCA_PIE_TUPDATE,
-			jiffies_to_msecs(q->params.tupdate)) ||
-	    nla_put_u32(skb, TCA_PIE_ALPHA, q->params.alpha) ||
+			(q->params.tupdate * 1000) / HZ) ||
+	    nla_put_u32(skb, TCA_PIE_ALPHA,
+			q->params.alpha) ||
 	    nla_put_u32(skb, TCA_PIE_BETA, q->params.beta) ||
 	    nla_put_u32(skb, TCA_PIE_BYTEMODE, q->params.small) ||
 	    nla_put_u32(skb, TCA_PIE_ECN, q->params.ecn))
+
 		goto nla_put_failure;
 
 	return nla_nest_end(skb, opts);
@@ -480,6 +507,8 @@ static void pie_reset(struct Qdisc *sch)
 	struct pie_sched_data *q = qdisc_priv(sch);
 	qdisc_reset_queue(sch);
 	pie_vars_init(&q->vars);
+
+	return;
 }
 
 static void pie_destroy(struct Qdisc *sch)
@@ -506,18 +535,22 @@ static struct Qdisc_ops pie_qdisc_ops __read_mostly = {
 
 static int __init pie_module_init(void)
 {
+	printk
+	    ("PIE scheduler for controlling delay (pie): Module registered \n");
 	return register_qdisc(&pie_qdisc_ops);
 }
 
 static void __exit pie_module_exit(void)
 {
+	printk
+	    ("PIE scheduler for controlling delay (pie): Module unregistered \n\n");
 	unregister_qdisc(&pie_qdisc_ops);
 }
 
 module_init(pie_module_init);
 module_exit(pie_module_exit);
 
-MODULE_DESCRIPTION("PIE (Proportional Integral controller Enhanced) scheduler");
+MODULE_DESCRIPTION
+    ("PIE (Proportional Intergal controller Enhanced) scheduler for controlling delay");
 MODULE_AUTHOR("Vijay Subramanian");
-MODULE_AUTHOR("Mythili Prabhu");
 MODULE_LICENSE("GPL");
-- 
1.7.9.5

