From 071701c58ed9ada9d095d0fdf4b8d59c8e1c9f4a Mon Sep 17 00:00:00 2001
From: Dave Taht <dave.taht@bufferbloat.net>
Date: Fri, 1 Nov 2013 17:02:05 -0700
Subject: [PATCH] pie: update to v3 patch submitted to netdev

with 1000 packets
---
 net/sched/sch_pie.c |  127 +++++++++++++++++++++------------------------------
 1 file changed, 53 insertions(+), 74 deletions(-)

diff --git a/net/sched/sch_pie.c b/net/sched/sch_pie.c
index 2689c87..2110526 100644
--- a/net/sched/sch_pie.c
+++ b/net/sched/sch_pie.c
@@ -39,7 +39,7 @@
 /* parameters used */
 struct pie_params {
 	psched_time_t target;	/* user specified target delay in pschedtime */
-	psched_time_t tupdate;	/* frequency with which the timer fires */
+	u32 tupdate;		/* frequency with which the timer fires (us) */
 	u32 limit;		/* number of packets that can be enqueued */
 	u32 alpha;		/* alpha and beta are between -4 and 4 */
 	u32 beta;		/* and are used for shift relative to 1 */
@@ -49,14 +49,14 @@ struct pie_params {
 
 /* variables used */
 struct pie_vars {
-	u32 prob;		  /* probability but scaled by u32 limit. */
+	u32 prob;		/* probability but scaled by u32 limit. */
 	psched_time_t burst_time;
 	psched_time_t qdelay;
 	psched_time_t qdelay_old;
-	u64 dq_count;		  /* measured in bytes */
+	u64 dq_count;		/* measured in bytes */
 	psched_time_t dq_tstamp;	/* drain rate */
-	u32 avg_dq_rate;	  /* bytes per pschedtime tick,scaled*/
-	u32 qlen_old;		  /* in bytes */
+	u32 avg_dq_rate;	/* bytes per pschedtime tick,scaled */
+	u32 qlen_old;		/* in bytes */
 };
 
 /* statistics gathering*/
@@ -80,9 +80,9 @@ static void pie_params_init(struct pie_params *params)
 {
 	params->alpha = 2;
 	params->beta = 20;
-	params->tupdate = PSCHED_NS2TICKS(30 * NSEC_PER_MSEC);	  /* 30 ms */
-	params->limit = 200;			 /* default of 200 packets */
-	params->target = PSCHED_NS2TICKS(20 * NSEC_PER_MSEC);	  /* 20 ms */
+	params->tupdate = 30 * USEC_PER_MSEC;	/* 30 ms */
+	params->limit = 1000;	/* default of 1000 packets */
+	params->target = PSCHED_NS2TICKS(20 * NSEC_PER_MSEC);	/* 20 ms */
 	params->ecn = false;
 	params->bytemode = false;
 }
@@ -102,8 +102,7 @@ static bool drop_early(struct Qdisc *sch, u32 packet_size)
 	u32 local_prob = q->vars.prob;
 	u32 mtu = psched_mtu(qdisc_dev(sch));
 
-	/* If there is still burst allowance left skip random early drop
-	 */
+	/* If there is still burst allowance left skip random early drop */
 	if (q->vars.burst_time > 0)
 		return false;
 
@@ -125,7 +124,7 @@ static bool drop_early(struct Qdisc *sch, u32 packet_size)
 	 */
 	if (q->params.bytemode && packet_size <= mtu)
 		local_prob = (local_prob / mtu) * packet_size;
-	 else
+	else
 		local_prob = q->vars.prob;
 
 	rnd = net_random();
@@ -152,11 +151,11 @@ static int pie_qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch)
 		return qdisc_enqueue_tail(skb, sch);
 	} else if (q->params.ecn && INET_ECN_set_ce(skb) &&
 		   (q->vars.prob <= MAX_PROB / 10)) {
-			/* If packet is ecn capable, mark it if drop probability
-			 * is lower than 10%, else drop it.
-			 */
-			q->stats.ecn_mark++;
-			return qdisc_enqueue_tail(skb, sch);
+		/* If packet is ecn capable, mark it if drop probability
+		 * is lower than 10%, else drop it.
+		 */
+		q->stats.ecn_mark++;
+		return qdisc_enqueue_tail(skb, sch);
 	}
 out:
 	q->stats.overlimit++;
@@ -164,13 +163,13 @@ out:
 }
 
 static const struct nla_policy pie_policy[TCA_PIE_MAX + 1] = {
-	[TCA_PIE_TARGET]   =  {.type = NLA_U32},
-	[TCA_PIE_LIMIT]    =  {.type = NLA_U32},
-	[TCA_PIE_TUPDATE]  =  {.type = NLA_U32},
-	[TCA_PIE_ALPHA]    =  {.type = NLA_U32},
-	[TCA_PIE_BETA]     =  {.type = NLA_U32},
-	[TCA_PIE_ECN]      =  {.type = NLA_U32},
-	[TCA_PIE_BYTEMODE] =  {.type = NLA_U32},
+	[TCA_PIE_TARGET] = {.type = NLA_U32},
+	[TCA_PIE_LIMIT] = {.type = NLA_U32},
+	[TCA_PIE_TUPDATE] = {.type = NLA_U32},
+	[TCA_PIE_ALPHA] = {.type = NLA_U32},
+	[TCA_PIE_BETA] = {.type = NLA_U32},
+	[TCA_PIE_ECN] = {.type = NLA_U32},
+	[TCA_PIE_BYTEMODE] = {.type = NLA_U32},
 };
 
 static int pie_change(struct Qdisc *sch, struct nlattr *opt)
@@ -194,15 +193,12 @@ static int pie_change(struct Qdisc *sch, struct nlattr *opt)
 		/* target is in us */
 		u32 target = nla_get_u32(tb[TCA_PIE_TARGET]);
 		/* convert to pschedtime */
-		q->params.target = PSCHED_NS2TICKS((u64) target * NSEC_PER_USEC);
+		q->params.target = PSCHED_NS2TICKS((u64)target * NSEC_PER_USEC);
 	}
 
-	if (tb[TCA_PIE_TUPDATE]) {
-		/* tupdate is in us */
-		u32 tupdate = nla_get_u32(tb[TCA_PIE_TUPDATE]);
-		/* convert to pschedtime */
-		q->params.tupdate = PSCHED_NS2TICKS((u64) tupdate * NSEC_PER_USEC);
-	}
+	/* tupdate is in us */
+	if (tb[TCA_PIE_TUPDATE])
+		q->params.tupdate = nla_get_u32(tb[TCA_PIE_TUPDATE]);
 
 	if (tb[TCA_PIE_LIMIT]) {
 		u32 limit = nla_get_u32(tb[TCA_PIE_LIMIT]);
@@ -236,7 +232,7 @@ static int pie_change(struct Qdisc *sch, struct nlattr *opt)
 	return 0;
 }
 
-static int pie_process_dequeue(struct Qdisc *sch, struct sk_buff *skb)
+static void pie_process_dequeue(struct Qdisc *sch, struct sk_buff *skb)
 {
 
 	struct pie_sched_data *q = qdisc_priv(sch);
@@ -246,7 +242,6 @@ static int pie_process_dequeue(struct Qdisc *sch, struct sk_buff *skb)
 	 *  we have enough packets to calculate the drain rate. Save
 	 *  current time as dq_tstamp and start measurement cycle.
 	 */
-
 	if (qlen >= QUEUE_THRESHOLD && q->vars.dq_count == DQCOUNT_INVALID) {
 		q->vars.dq_tstamp = psched_get_time();
 		q->vars.dq_count = 0;
@@ -267,17 +262,13 @@ static int pie_process_dequeue(struct Qdisc *sch, struct sk_buff *skb)
 
 		if (q->vars.dq_count >= QUEUE_THRESHOLD) {
 			psched_time_t now = psched_get_time();
-			psched_tdiff_t dtime = now - q->vars.dq_tstamp;
+			u32 dtime = now - q->vars.dq_tstamp;
 			u32 count = q->vars.dq_count << PIE_SCALE;
 
 			if (dtime == 0)
-				return 0;
+				return;
 
-			/* dtime has overflowed */
-			if (dtime < 0)
-				dtime = -dtime;
-
-			count = count/dtime;
+			count = count / dtime;
 
 			if (q->vars.avg_dq_rate == 0)
 				q->vars.avg_dq_rate = count;
@@ -291,7 +282,6 @@ static int pie_process_dequeue(struct Qdisc *sch, struct sk_buff *skb)
 			 * dq_count to 0 to re-enter the if block when the next
 			 * packet is dequeued
 			 */
-
 			if (qlen < QUEUE_THRESHOLD)
 				q->vars.dq_count = DQCOUNT_INVALID;
 			else {
@@ -307,7 +297,6 @@ static int pie_process_dequeue(struct Qdisc *sch, struct sk_buff *skb)
 			}
 		}
 	}
-	return 0;
 }
 
 static void calculate_probability(struct Qdisc *sch)
@@ -316,10 +305,10 @@ static void calculate_probability(struct Qdisc *sch)
 	u32 qlen = sch->qstats.backlog;	/* queue size in bytes */
 	psched_time_t qdelay = 0;	/* in pschedtime */
 	psched_time_t qdelay_old = q->vars.qdelay;	/* in pschedtime */
-	s32 delta = 0;		/* signed difference */
+	s32 delta = 0;		/* determines the change in probability  */
 	u32 oldprob;
 	u32 alpha, beta;
-	bool update_prob = true;	/* Should probability be updated? */
+	bool update_prob = true;
 
 	q->vars.qdelay_old = q->vars.qdelay;
 
@@ -366,9 +355,9 @@ static void calculate_probability(struct Qdisc *sch)
 	/* addition to ensure we increase probability in steps of no
 	 *  more than 2%
 	 */
-
-	if (delta > (s32)(MAX_PROB / (100/2)) && q->vars.prob >= MAX_PROB/10)
-		delta = MAX_PROB * 2 / 100;
+	if (delta > (s32) (MAX_PROB / (100 / 2))
+	    && q->vars.prob >= MAX_PROB / 10)
+		delta = (MAX_PROB / 100) * 2;
 
 	/*  Non-linear drop
 	 *  Tune drop probability to increase quickly for high delays
@@ -377,7 +366,7 @@ static void calculate_probability(struct Qdisc *sch)
 	 */
 
 	if (qdelay > (PSCHED_NS2TICKS(250 * NSEC_PER_MSEC)))
-		delta +=  MAX_PROB / (100/2);
+		delta += MAX_PROB / (100 / 2);
 
 	q->vars.prob += delta;
 
@@ -425,20 +414,16 @@ static void pie_timer(unsigned long arg)
 {
 	struct Qdisc *sch = (struct Qdisc *)arg;
 	struct pie_sched_data *q = qdisc_priv(sch);
-	u32 tup;
 	spinlock_t *root_lock = qdisc_lock(qdisc_root_sleeping(sch));
 
 	spin_lock(root_lock);
 	calculate_probability(sch);
-	/* reset the timer to fire after 'tupdate' us,
-	 * tupdate is currently in psched_time
-	 * mod_timer expects time to be in jiffies
-	 */
-	/* convert from pschedtime to nsecs to ms*/
-	tup = PSCHED_TICKS2NS(q->params.tupdate)/NSEC_PER_MSEC;
-	tup = (tup * HZ) / MSEC_PER_SEC;	/* and thence to  jiffies */
 
-	mod_timer(&q->adapt_timer, jiffies + tup);
+	/* reset the timer to fire after 'tupdate'. Convert from us to jiffies.
+	 */
+	if (q->params.tupdate)
+		mod_timer(&q->adapt_timer, jiffies +
+			  usecs_to_jiffies(q->params.tupdate));
 	spin_unlock(root_lock);
 
 }
@@ -452,7 +437,7 @@ static int pie_init(struct Qdisc *sch, struct nlattr *opt)
 	sch->limit = q->params.limit;
 
 	setup_timer(&q->adapt_timer, pie_timer, (unsigned long)sch);
-	mod_timer(&q->adapt_timer, jiffies + HZ/2);
+	mod_timer(&q->adapt_timer, jiffies + HZ / 2);
 
 	if (opt) {
 		int err = pie_change(sch, opt);
@@ -473,15 +458,13 @@ static int pie_dump(struct Qdisc *sch, struct sk_buff *skb)
 	if (opts == NULL)
 		goto nla_put_failure;
 
-	/* convert target and tupdate from pschedtime to us */
+	/* convert target from pschedtime to us */
 	if (nla_put_u32(skb, TCA_PIE_TARGET,
-			PSCHED_TICKS2NS(q->params.target) / NSEC_PER_USEC) ||
-	    nla_put_u32(skb, TCA_PIE_LIMIT,
-			sch->limit) ||
-	    nla_put_u32(skb, TCA_PIE_TUPDATE,
-			PSCHED_TICKS2NS(q->params.tupdate) / NSEC_PER_USEC) ||
-	    nla_put_u32(skb, TCA_PIE_ALPHA,
-			q->params.alpha) ||
+			((u32) PSCHED_TICKS2NS(q->params.target)) /
+			NSEC_PER_USEC) ||
+	    nla_put_u32(skb, TCA_PIE_LIMIT, sch->limit) ||
+	    nla_put_u32(skb, TCA_PIE_TUPDATE, q->params.tupdate) ||
+	    nla_put_u32(skb, TCA_PIE_ALPHA, q->params.alpha) ||
 	    nla_put_u32(skb, TCA_PIE_BETA, q->params.beta) ||
 	    nla_put_u32(skb, TCA_PIE_ECN, q->params.ecn) ||
 	    nla_put_u32(skb, TCA_PIE_BYTEMODE, q->params.bytemode))
@@ -500,8 +483,8 @@ static int pie_dump_stats(struct Qdisc *sch, struct gnet_dump *d)
 	struct pie_sched_data *q = qdisc_priv(sch);
 	struct tc_pie_xstats st = {
 		.prob		= q->vars.prob,
-		.delay		= PSCHED_TICKS2NS(q->vars.qdelay) /
-				  NSEC_PER_USEC,	/* in us */
+		.delay		= ((u32) PSCHED_TICKS2NS(q->vars.qdelay)) /
+				   NSEC_PER_USEC,
 		/* unscale and return dq_rate in bytes per sec */
 		.avg_dq_rate	= q->vars.avg_dq_rate *
 				  (PSCHED_TICKS_PER_SEC) >> PIE_SCALE,
@@ -515,7 +498,7 @@ static int pie_dump_stats(struct Qdisc *sch, struct gnet_dump *d)
 	return gnet_stats_copy_app(d, &st, sizeof(st));
 }
 
-static inline struct sk_buff *pie_qdisc_dequeue(struct Qdisc *sch)
+static struct sk_buff *pie_qdisc_dequeue(struct Qdisc *sch)
 {
 	struct sk_buff *skb;
 	skb = __qdisc_dequeue_head(sch, &sch->q);
@@ -524,7 +507,6 @@ static inline struct sk_buff *pie_qdisc_dequeue(struct Qdisc *sch)
 		return NULL;
 
 	pie_process_dequeue(sch, skb);
-
 	return skb;
 }
 
@@ -533,21 +515,18 @@ static void pie_reset(struct Qdisc *sch)
 	struct pie_sched_data *q = qdisc_priv(sch);
 	qdisc_reset_queue(sch);
 	pie_vars_init(&q->vars);
-
-	return;
 }
 
 static void pie_destroy(struct Qdisc *sch)
 {
 	struct pie_sched_data *q = qdisc_priv(sch);
-
+	q->params.tupdate = 0;
 	del_timer_sync(&q->adapt_timer);
 }
 
 static struct Qdisc_ops pie_qdisc_ops __read_mostly = {
 	.id = "pie",
-	.priv_size = sizeof(struct pie_sched_data),
-
+	.priv_size	= sizeof(struct pie_sched_data),
 	.enqueue	= pie_qdisc_enqueue,
 	.dequeue	= pie_qdisc_dequeue,
 	.peek		= qdisc_peek_dequeued,
-- 
1.7.9.5

